/**
 * Basic Machine Learning Module for Tocin
 * Provides basic ML algorithms and utilities
 */

module ml.basic {
    import math;
    import math.vector.{Vector};
    import math.matrix.{Matrix};
    
    // Linear Regression implementation
    export class LinearRegression {
        private weights: list<float64>;
        private bias: float64;
        private fitted: bool = false;
        
        constructor() {
            this.weights = [];
            this.bias = 0.0;
        }
        
        // Fit the model to training data
        def fit(X: list<list<float64>>, y: list<float64>, learningRate: float64 = 0.01, epochs: int = 1000) {
            let n_samples = X.length();
            if (n_samples == 0) return;
            
            let n_features = X[0].length();
            
            // Initialize weights and bias
            this.weights = [];
            for i in 0..n_features {
                this.weights.push(0.0);
            }
            this.bias = 0.0;
            
            // Gradient descent
            for epoch in 0..epochs {
                // Forward pass: y_pred = X * weights + bias
                let y_pred = [];
                for i in 0..n_samples {
                    let sum = this.bias;
                    for j in 0..n_features {
                        sum += X[i][j] * this.weights[j];
                    }
                    y_pred.push(sum);
                }
                
                // Compute gradients
                let dw = [];
                for j in 0..n_features {
                    dw.push(0.0);
                }
                
                let db = 0.0;
                
                for i in 0..n_samples {
                    let error = y_pred[i] - y[i];
                    
                    // Update bias gradient
                    db += error;
                    
                    // Update weight gradients
                    for j in 0..n_features {
                        dw[j] += error * X[i][j];
                    }
                }
                
                // Normalize gradients
                db /= n_samples;
                for j in 0..n_features {
                    dw[j] /= n_samples;
                }
                
                // Update parameters
                this.bias -= learningRate * db;
                for j in 0..n_features {
                    this.weights[j] -= learningRate * dw[j];
                }
            }
            
            this.fitted = true;
        }
        
        // Predict using the fitted model
        def predict(X: list<list<float64>>) -> list<float64> {
            if !this.fitted {
                throw "Model must be fitted before prediction";
            }
            
            let n_samples = X.length();
            if (n_samples == 0) return [];
            
            let n_features = X[0].length();
            
            // Check if input dimensions match the model
            if n_features != this.weights.length() {
                throw "Input features dimension does not match model features";
            }
            
            // Make predictions
            let predictions = [];
            for i in 0..n_samples {
                let pred = this.bias;
                for j in 0..n_features {
                    pred += X[i][j] * this.weights[j];
                }
                predictions.push(pred);
            }
            
            return predictions;
        }
        
        // Calculate R-squared score for model evaluation
        def score(X: Matrix<float64>, y: Vector<float64>) -> float64 {
            let y_pred = this.predict(X);
            
            // Calculate total sum of squares
            let y_mean = 0.0;
            for i in 0..y.dimension() {
                y_mean += y.get(i);
            }
            y_mean /= y.dimension();
            
            let ss_tot = 0.0;
            let ss_res = 0.0;
            
            for i in 0..y.dimension() {
                let y_true = y.get(i);
                let y_p = y_pred[i];
                
                ss_tot += (y_true - y_mean) * (y_true - y_mean);
                ss_res += (y_true - y_p) * (y_true - y_p);
            }
            
            // R^2 = 1 - (residual sum of squares / total sum of squares)
            if ss_tot == 0.0 {
                return 0.0;  // Avoid division by zero
            }
            
            return 1.0 - (ss_res / ss_tot);
        }
        
        // Get model coefficients
        def getCoefficients() -> list<float64> {
            return this.weights;
        }
        
        // Get model intercept
        def getIntercept() -> float64 {
            return this.bias;
        }
    }
    
    // K-Nearest Neighbors implementation
    export class KNearestNeighbors {
        private k: int;
        private X_train: Matrix<float64>;
        private y_train: Vector<int>;
        private fitted: bool = false;
        
        constructor(k: int = 3) {
            this.k = k;
        }
        
        // Fit the model to training data
        def fit(X: Matrix<float64>, y: Vector<int>) {
            this.X_train = X;
            this.y_train = y;
            this.fitted = true;
        }
        
        // Calculate Euclidean distance between two points
        private def euclideanDistance(x1: list<float64>, x2: list<float64>) -> float64 {
            let sum = 0.0;
            for i in 0..x1.length() {
                let diff = x1[i] - x2[i];
                sum += diff * diff;
            }
            return math.sqrt(sum);
        }
        
        // Predict class for a single sample
        private def predictOne(x: list<float64>) -> int {
            if !this.fitted {
                throw "Model must be fitted before prediction";
            }
            
            // Calculate distances to all training samples
            let distances = new list<tuple<float64, int>>();
            for i in 0..this.X_train.rows {
                let row = new list<float64>();
                for j in 0..this.X_train.cols {
                    row.push(this.X_train.get(i, j));
                }
                
                let dist = this.euclideanDistance(x, row);
                distances.push((dist, this.y_train.get(i)));
            }
            
            // Sort distances
            distances.sort((a, b) => a.0 < b.0);
            
            // Count votes for the k nearest neighbors
            let votes = new dict<int, int>();
            for i in 0..this.k {
                if i >= distances.length() {
                    break;
                }
                
                let label = distances[i].1;
                if label in votes {
                    votes[label] += 1;
                } else {
                    votes[label] = 1;
                }
            }
            
            // Find the class with the most votes
            let maxVotes = 0;
            let predictedClass = 0;
            
            for label, count in votes {
                if count > maxVotes {
                    maxVotes = count;
                    predictedClass = label;
                }
            }
            
            return predictedClass;
        }
        
        // Predict classes for multiple samples
        def predict(X: Matrix<float64>) -> Vector<int> {
            let predictions = new list<int>();
            
            for i in 0..X.rows {
                let sample = new list<float64>();
                for j in 0..X.cols {
                    sample.push(X.get(i, j));
                }
                
                predictions.push(this.predictOne(sample));
            }
            
            return new Vector<int>(predictions);
        }
        
        // Calculate accuracy score for model evaluation
        def score(X: Matrix<float64>, y: Vector<int>) -> float64 {
            let y_pred = this.predict(X);
            
            let correct = 0;
            for i in 0..y.dimension() {
                if y_pred.get(i) == y.get(i) {
                    correct += 1;
                }
            }
            
            return correct as float64 / y.dimension() as float64;
        }
    }
    
    // Data standardization (z-score normalization)
    export def standardize(X: Matrix<float64>) -> Matrix<float64> {
        let result = new Matrix<float64>(X.rows, X.cols);
        
        // Calculate mean and standard deviation for each feature
        for j in 0..X.cols {
            let mean = 0.0;
            for i in 0..X.rows {
                mean += X.get(i, j);
            }
            mean /= X.rows as float64;
            
            let variance = 0.0;
            for i in 0..X.rows {
                let diff = X.get(i, j) - mean;
                variance += diff * diff;
            }
            variance /= X.rows as float64;
            
            let std_dev = math.sqrt(variance);
            
            // Avoid division by zero
            if std_dev == 0.0 {
                std_dev = 1.0;
            }
            
            // Standardize the feature
            for i in 0..X.rows {
                result.set(i, j, (X.get(i, j) - mean) / std_dev);
            }
        }
        
        return result;
    }
    
    // Mean Squared Error calculation
    export def meanSquaredError(y_true: Vector<float64>, y_pred: Vector<float64>) -> float64 {
        if y_true.dimension() != y_pred.dimension() {
            throw "Vectors must have the same dimension";
        }
        
        let sum = 0.0;
        for i in 0..y_true.dimension() {
            let diff = y_true.get(i) - y_pred.get(i);
            sum += diff * diff;
        }
        
        return sum / y_true.dimension() as float64;
    }
    
    // Mean Absolute Error calculation
    export def meanAbsoluteError(y_true: Vector<float64>, y_pred: Vector<float64>) -> float64 {
        if y_true.dimension() != y_pred.dimension() {
            throw "Vectors must have the same dimension";
        }
        
        let sum = 0.0;
        for i in 0..y_true.dimension() {
            let diff = y_true.get(i) - y_pred.get(i);
            sum += math.abs(diff);
        }
        
        return sum / y_true.dimension() as float64;
    }
    
    // Accuracy calculation for classification
    export def accuracy(y_true: Vector<int>, y_pred: Vector<int>) -> float64 {
        if y_true.dimension() != y_pred.dimension() {
            throw "Vectors must have the same dimension";
        }
        
        let correct = 0;
        for i in 0..y_true.dimension() {
            if y_true.get(i) == y_pred.get(i) {
                correct += 1;
            }
        }
        
        return correct as float64 / y_true.dimension() as float64;
    }
    
    // Min-max scaling
    export def minMaxScale(X: Matrix<float64>, min: float64 = 0.0, max: float64 = 1.0) -> Matrix<float64> {
        let result = new Matrix<float64>(X.rows, X.cols);
        
        // Find min and max for each feature
        for j in 0..X.cols {
            let col_min = X.get(0, j);
            let col_max = X.get(0, j);
            
            for i in 1..X.rows {
                let val = X.get(i, j);
                if val < col_min {
                    col_min = val;
                }
                if val > col_max {
                    col_max = val;
                }
            }
            
            // Avoid division by zero
            let range = col_max - col_min;
            if range == 0.0 {
                range = 1.0;
            }
            
            // Scale the feature
            for i in 0..X.rows {
                let scaled = (X.get(i, j) - col_min) / range;
                result.set(i, j, scaled * (max - min) + min);
            }
        }
        
        return result;
    }
    
    // Train-test split
    export def trainTestSplit<T>(
        X: Matrix<float64>, 
        y: Vector<T>, 
        testSize: float64 = 0.2, 
        seed: int = 42
    ) -> tuple<Matrix<float64>, Matrix<float64>, Vector<T>, Vector<T>> {
        if X.rows != y.dimension() {
            throw "Number of samples in X and y must match";
        }
        
        if testSize <= 0.0 || testSize >= 1.0 {
            throw "Test size must be between 0 and 1";
        }
        
        let n_samples = X.rows;
        let n_features = X.cols;
        
        // Set random seed
        @extern("random", "seed")
        def _random_seed(seed: int);
        _random_seed(seed);
        
        // Create random indices
        let indices = new list<int>(n_samples);
        for i in 0..n_samples {
            indices[i] = i;
        }
        
        // Shuffle indices
        @extern("random", "shuffle")
        def _random_shuffle(arr: list<int>);
        _random_shuffle(indices);
        
        // Calculate split point
        let test_size = (testSize * n_samples as float64) as int;
        if test_size < 1 {
            test_size = 1;
        } else if test_size >= n_samples {
            test_size = n_samples - 1;
        }
        
        let train_size = n_samples - test_size;
        
        // Create train and test sets
        let X_train = new Matrix<float64>(train_size, n_features);
        let X_test = new Matrix<float64>(test_size, n_features);
        
        let y_train_list = new list<T>(train_size);
        let y_test_list = new list<T>(test_size);
        
        // Populate train set
        for i in 0..train_size {
            let idx = indices[i];
            for j in 0..n_features {
                X_train.set(i, j, X.get(idx, j));
            }
            y_train_list[i] = y.get(idx);
        }
        
        // Populate test set
        for i in 0..test_size {
            let idx = indices[i + train_size];
            for j in 0..n_features {
                X_test.set(i, j, X.get(idx, j));
            }
            y_test_list[i] = y.get(idx);
        }
        
        let y_train = new Vector<T>(y_train_list);
        let y_test = new Vector<T>(y_test_list);
        
        return (X_train, X_test, y_train, y_test);
    }
} 
